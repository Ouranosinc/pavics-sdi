{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2ec94ba",
   "metadata": {},
   "source": [
    "# Regridding climate data with xESMF\n",
    "\n",
    "A common element of climate data workflows is regridding, or reprojection, of model data unto more standard grids, or simply unto another dataset's grid. The powerful [ESMF](http://earthsystemmodeling.org/docs/release/ESMF_8_0_1/ESMF_usrdoc/) program, written in FORTRAN, has long been a reference in the matter. The [xESMF](https://pangeo-xesmf.readthedocs.io/en/latest/) python package provides an easy to use high-level API for using ESMF's methods. This notebook shows some examples of common regridding operations.\n",
    "\n",
    "Regridding with `xESMF` is usually a two step process: \n",
    "\n",
    " 1. Create a `Regridder` objects from two datasets, defining the input and the output grids. This compute a weights mask which can, if needed, be saved to a netCDCF file.\n",
    " 2. Regrid a DataArray or Dataset by calling the `Regridder` with it. As the weights have already been computed, it reuses them for all time slices, which allows much better performance than, for example, interpolation using `scipy.interpolation.interpn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8961656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# ipykernel_launcher.py:1: DeprecationWarning: xclim.subset is deprecated in xclim v0.19.1-beta. Please take note that xclim presently exposes the 'clisops' library subsetting API via `from clisops.core import subset`.\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from xclim.subset import subset_bbox  # For subsetting\n",
    "from xclim.testing import open_dataset  # For opening xclim's test data\n",
    "import cf_xarray as cfxr\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "\n",
    "# Other utilities for style and clean examples\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  A colormap with grey where the data is missing\n",
    "cmap = copy.copy(plt.cm.get_cmap('viridis'))\n",
    "cmap.set_bad('lightgray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc260ef",
   "metadata": {},
   "source": [
    "## Simple example : Bilinear regridding from model to obs\n",
    "\n",
    "Our input in this example is a year of monthly sea ice concentration data from a CanESM5 run for CMIP6. It lies on an irregular grid defined by `latitude` and `longitude` coordinates. We'll interpolate the sea ice concentration to a regular observational grid from Natural Resources Canada. \n",
    "\n",
    "### The input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f4f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# The input test data is hosted on the Ouranos THREDDS\n",
    "url = \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/testdata/xclim/cmip6/sic_SImon_CCCma-CanESM5_ssp245_r13i1p2f1_2020.nc\"\n",
    "ds_in = xr.open_dataset(url)\n",
    "ds_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb479839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the grid shape itself and the data for one time step\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "\n",
    "ds_in.plot.scatter(x='longitude', y='latitude', s=0.1, ax=axs[0])\n",
    "axs[0].set_title('The input horizontal grid points as seen on a lat/lon map.\\nOnly the northern hemisphere is shown.')\n",
    "axs[0].set_ylim(0, 90)\n",
    "\n",
    "ds_in.siconc.isel(time=0).plot(ax=axs[1], cmap=cmap)\n",
    "axs[1].set_title('Sea Ice concentration on Jan 2020, original grid')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774a809",
   "metadata": {},
   "source": [
    "### The output grid\n",
    "\n",
    "The NRCAN observations' dataset uses a simple rectangular lat/lon grid over Canada at about 10km resolution. To reduce computation time for this example, we'll first crop the grid to include only Hudson Bay and the Labrador Sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "url_obs = \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/nrcan/nrcan_canada_daily_v2/nrcan_canada_daily_V2-allvars-agg.ncml\"\n",
    "\n",
    "# For this example, we're not interested in the observation data, only its underlying grid, so we'll select a single time step. \n",
    "ds_obs = xr.open_dataset(url_obs).sel(time='1993-05-20')\n",
    "\n",
    "# Subset over the Hudson Bay and the Labrador Sea for the example\n",
    "bbox = dict(lon_bnds=[-99.5, -41.92], lat_bnds=[50.35, 67.61])\n",
    "ds_tgt = subset_bbox(ds_obs, **bbox)\n",
    "ds_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27481774",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tgt.cf.plot.scatter(x='longitude', y='latitude', s=0.1)\n",
    "plt.title('Target regular grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68784a4a",
   "metadata": {},
   "source": [
    "xESMF relies on the useful [cf_xarray](https://cf-xarray.readthedocs.io/en/latest/) package to infer which variables are the latitude and longitude points. It will automatically know to use `longitude` and `latitude` on the datasets because their attributes are correctly set, as `ds.cf.describe()`  shows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_in.cf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdbfda",
   "metadata": {},
   "source": [
    "If those attributes were **not** set, we would need to rename the coordinates to `lon` and `lat`, xESMF's default's coordinate names.\n",
    "\n",
    "### Regridding input data unto the output grid\n",
    "\n",
    "First we create the regridding object, using the \"bilinear\" method, and then simply call it with the array that we want regridded (here `siconc`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_bil = xe.Regridder(ds_in, ds_tgt, 'bilinear')\n",
    "reg_bil  # Show information about the regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5487ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xesmf/frontend.py:476: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Apply the regridding weights to the input sea ice concentration data\n",
    "sic_bil = reg_bil(ds_in.siconc)\n",
    "\n",
    "# Plot the results\n",
    "sic_bil.isel(time=0).plot(cmap=cmap)\n",
    "plt.title('Regridded sic data (Jan 2020)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dab540",
   "metadata": {},
   "source": [
    "The output now has the same grid as the target! The regridding operation was broadcasted along the non spatial dimensions (here `time`), so that all time steps were regridded using the same pre-computed weights.\n",
    "\n",
    "## Second example : Conservative regridding and reusing weights\n",
    "\n",
    "xESMF provides the following regridding methods : \"bilinear\", \"conservative\", \"conservative_normed\", \"nearest_s2d\", \"nearest_d2s\" and \"patch\" (see [method descriptions](https://earthsystemmodeling.org/regrid/#regridding-methods)). Conservative methods preserve areal averages, and for these methods we need to provide the coordinates of the grid cells' corners rather than the coordinates at the cells center.\n",
    "\n",
    "### Untangling corners definitions\n",
    "\n",
    "Before we go further, it's worth highlighting differences between xESMF's description of corner coordinates and how the same information is stored in CF-compliant files. \n",
    "\n",
    "For an `N x M` lon/lat grid,  xESMF expects an array with one element more than the coordinates. For example, on a regular grid, the corner of point at `lon[0]` are given by `lon_b[0]` and `lon_b[1]`. However, in a typical CF-compliant file, *grid corner* information is in an array of shape (N, 2) typically called `lon_bounds` and `lat_bounds`. Thus, the western and eastern corners of point at `lon[0]` are given by `lon_corners[0, 0]` and `lon_corners[0, 1]`. \n",
    "\n",
    "The `cf_xarray` package differentiates the two concepts by naming the CF-compliant one \"bounds\" and the xESMF one \"vertices\". However, CF conventions sometime uses vertices and bound interchangeably, and in our model dataset, the `vertices_longitude` variable stores corners according to the \"bounds\" definition...  We will nevetheless stick with `cf_xarray`'s nomenclature in the following.\n",
    "\n",
    "The table below summarizes the difference between the two versions:\n",
    "\n",
    "|                        | bounds    | vertices   |\n",
    "|------------------------|-------------|--------------|\n",
    "| CF-compliant           | Yes         | No           |\n",
    "| Shape (regular grid)   | (N, 2)      | (N+1,)       |\n",
    "| Shape (irregular grid) | (Nx, Ny, 4) | (Nx+1, Ny+1) |\n",
    "\n",
    "\n",
    "### Computing the corners\n",
    "\n",
    "The corners of regular grids (1D lat/lon) are infered automatically if not given. This will be the case for our `ds_tgt` dataset.\n",
    "\n",
    "For irregular grids, `xESMF` will check for variables `lon_b` and `lat_b`, or try automatic detection with the help of `cf_xarray`. If they are found, it uses `cf_xarray`'s method to convert from the CF-compliant \"bounds\" to the required \"vertices\" syntax. However, a small bug in xESMF 0.5.2 prevents use from using this feature with our model dataset. We will convert the corner variables ourselves from the CF-compliant format we have to the format xESMF expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fc32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bounds variable and convert them to \"vertices\" format\n",
    "# Order=none, means that we do not know if the bounds are listed clockwise or counterclockwise, so we ask cf_xarray to try both.\n",
    "lat_corners = cfxr.bounds_to_vertices(ds_in.vertices_latitude, 'vertices', order=None)\n",
    "lon_corners = cfxr.bounds_to_vertices(ds_in.vertices_longitude, 'vertices', order=None)\n",
    "ds_in_crns = ds_in.assign(lon_b=lon_corners, lat_b=lat_corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deedb74",
   "metadata": {},
   "source": [
    "### Regridding\n",
    "\n",
    "The regridding process is as simple as above now that `ds_in_crns` contains the corner coordinates (`lon_b`, `lat_b`). Here we also pass a filename, so that the weights are saved to disk and can be reused (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40afa120",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reg_cons = xe.Regridder(ds_in_crns, ds_tgt, 'conservative', filename='conservative_regridder.nc')\n",
    "print(reg_cons)\n",
    "\n",
    "# Regrid as before\n",
    "sic_cons = reg_cons(ds_in_crns.siconc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0058b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at the results\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14, 4))\n",
    "\n",
    "sic_bil.isel(time=0).plot(ax=axs[0], cmap=cmap)\n",
    "axs[0].set_title('Method: Bilinear')\n",
    "\n",
    "sic_cons.isel(time=0).plot(ax=axs[1], cmap=cmap)\n",
    "axs[1].set_title('Method: Conservative')\n",
    "\n",
    "# A divergent colormap with gray on missing values\n",
    "cmap_div = copy.copy(plt.cm.get_cmap('RdBu'))\n",
    "cmap_div.set_bad('lightgray')\n",
    "(sic_bil - sic_cons).isel(time=0).plot(ax=axs[2], cmap=cmap_div, vmin=-40, vmax=40)\n",
    "diff_NaNs = (sic_bil.isnull() ^ sic_cons.isnull()).isel(time=0)\n",
    "diff_NaNs.where(diff_NaNs).plot(cmap=plt.cm.Greens, ax=axs[2], vmin=0, add_colorbar=False)\n",
    "axs[2].set_title('Bilinear minus Conservative\\nGreen indicates missing values in one but not the other')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4ef0d",
   "metadata": {},
   "source": [
    "As we can see, \"bilinear\" regridding results in a smooth output field, while \"conservative\" results preserves the original data's coarser resolution. In the last panel, the green cells show that the two methods have different missing values results. In our case of increasing resolution, there will often be more missing values when using \"bilinear\". The next example explains how xESMF can explictely manage missing values. But before, we look at the reusability of the weights generated by xESMF.\n",
    "\n",
    "### Reusing weights\n",
    "\n",
    "The weights of the previous regridding have been written to disk. We can simply reuse them by specifying that filename and passing `reuse_weights=True`. You'll notice how faster the process is, as we don't compute the weights again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "reg_bis = xe.Regridder(ds_in_crns, ds_tgt, 'conservative', reuse_weights=True, filename='conservative_regridder.nc')\n",
    "print(reg_bis)\n",
    "\n",
    "# Regrid as before\n",
    "sic_bis = reg_bis(ds_in_crns.siconc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2fcbd1",
   "metadata": {},
   "source": [
    "## Third example : Regridding and masks\n",
    "\n",
    "By defaut, xESMF doesn't handle missing values in a special way, so when they are present in the input data they often bleed into the regridded field, especially when decreasing resolution. This example demonstrates this bleeding effect and how it can be mitigated using masks.\n",
    "\n",
    "We will use a global model dataset and try to regrid the NRCAN observation unto the global grid, thus decreasing the resolution.\n",
    "\n",
    "\n",
    "### Target grid and mask\n",
    "\n",
    "The target grid will be the CanESM2 model grid, but with the ocean masked. In the following, we fetch both the \"tasmin\" data for the same date as the obs and the \"sftlf\" mask so we can obtain a land mask (land fraction above 0.25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40cc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Model data for tasmin\n",
    "ds_tgt = xr.open_dataset('https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/cccma/CanESM2/historical/day/atmos/r1i1p1/tasmin/tasmin_day_CanESM2_historical_r1i1p1_18500101-20051231.nc')\n",
    "# Land-sea fraction\n",
    "ds_sftlf = xr.open_dataset('https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/cccma/CanESM2/historical/fx/atmos/r0i0p0/sftlf/sftlf_fx_CanESM2_historical_r0i0p0.nc')\n",
    "ds_tgt = ds_tgt.sel(time='1993-05-20')  # Extract same day as obs\n",
    "ds_tgt = ds_tgt.rename(bnds='bounds')  # Small fix for xESMF 0.5.2\n",
    "ds_tgt['tasmin'] = ds_tgt.tasmin.where(ds_sftlf.sftlf > 0.25)  # Mask tasmin data that is over the ocean\n",
    "ds_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Input grid and data : reuse ds_obs (NRCAN but without the subsetting)\n",
    "ds_in = ds_obs[[\"tasmin\"]]\n",
    "ds_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0a962",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "\n",
    "ds_in.tasmin.plot(ax=axs[0], cmap=cmap)\n",
    "axs[0].set_title('NRCAN Input grid')\n",
    "\n",
    "ds_tgt.tasmin.plot(ax=axs[1], cmap=cmap)\n",
    "axs[1].set_title('Target CanESM2 grid')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7282b2b4",
   "metadata": {},
   "source": [
    "### Default regridding - No mask handling\n",
    "\n",
    "We first naïvely try the regridding exactly as before. Here we use the \"conservative_normed\" method, the reason is explained at the end of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd977d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_nomask = xe.Regridder(ds_in, ds_tgt, 'conservative_normed')\n",
    "print(reg_nomask)\n",
    "tasmin_nomask = reg_nomask(ds_in.tasmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46605fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "\n",
    "tasmin_nomask.plot(ax=axs[0], cmap=cmap)\n",
    "axs[0].set_title('Regridded NRCAN - No mask handling')\n",
    "\n",
    "tasmin_nomask.plot(ax=axs[1], cmap=cmap, vmin=255)\n",
    "axs[1].set_xlim(210, 320)\n",
    "axs[1].set_ylim(38, 86)\n",
    "axs[1].set_title('Zoom on Canada + Color rescaling')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76be24",
   "metadata": {},
   "source": [
    "This ugly result is the default behaviour of xESMF when no mask information is passed :\n",
    "\n",
    "1. A single missing value in the input suffices so that the target (coarser) grid cell is marked as missing. This erased all the Canadian Arctic Archipelago and most points near the sea in general.\n",
    "2. Grid points outside the input grid are filled with 0s instead of NaNs. \n",
    "\n",
    "To resolve this, we pass as binary mask to xESMF. xESMF will then exclude the masked values from the computation, and this way the small islands in the Canadian Arctic Archipelago won't be hidden by missing values. It will also activate a mode where values outside the input grid are marked as missing (NaN), which is usually more useful.\n",
    "\n",
    "Note that ESMF masks defined as `True` where data is valid, and `False` where it is missing. The variable must be named `mask` to get picked up by xESMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the masks and assign them as variables for both the input and output datasets. \n",
    "in_mask = ds_in.tasmin.notnull()\n",
    "ds_in_mask = ds_in.assign(mask=in_mask)\n",
    "\n",
    "tgt_mask = ds_tgt.tasmin.isel(time=0).notnull()\n",
    "ds_tgt_mask = ds_tgt.assign(mask=tgt_mask)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "in_mask.plot(ax=axs[0], cmap=plt.cm.binary_r, add_colorbar=False)\n",
    "tgt_mask.plot(ax=axs[1], cmap=plt.cm.binary_r, add_colorbar=False)\n",
    "axs[0].set_title('Input grid mask')\n",
    "axs[1].set_title('Target grid mask')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_mask = xe.Regridder(ds_in_mask, ds_tgt_mask, 'conservative_normed')\n",
    "reg_mask # Show information about the regriddingaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572e036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmin_mask = reg_mask(ds_in_mask.tasmin)\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "\n",
    "tasmin_mask.plot(ax=axs[0], cmap=cmap)\n",
    "axs[0].set_title('Regridded NRCAN - With mask handling')\n",
    "\n",
    "tasmin_mask.plot(ax=axs[1], cmap=cmap)\n",
    "axs[1].set_xlim(210, 320)\n",
    "axs[1].set_ylim(38, 86)\n",
    "axs[1].set_title('Zoom on Canada')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd8504",
   "metadata": {},
   "source": [
    "Much better! As expected, grid cells near the sea are kept and points outside the input grid are marked as missing.\n",
    "\n",
    "### Normalization for conservative regridding\n",
    "\n",
    "The \"conservative_normed\" method includes information about the missing values in the final normalization of the data. On the other hand, the \"conservative\" method normalizes using the total area of the target cell, no matter how many input grid points were valid. The following figure shows how that can lead to large biases in the data near the boundaries. Indeed, in the example below, the temperatures reach values close to 0 Kelvins near the boundaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766dcf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_mask_cons = xe.Regridder(ds_in_mask, ds_tgt_mask, 'conservative')\n",
    "tasmin_mask_cons = reg_mask_cons(ds_in_mask.tasmin)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "tasmin_mask_cons.plot(cmap=cmap, ax=ax)\n",
    "ax.set_xlim(210, 320)\n",
    "ax.set_ylim(38, 86)\n",
    "ax.set_title('Conservative regridding without normalization - zoom on Canada')\n",
    "ax.annotate(\"Some values are close to 0 Kelvins.\\nCanada can get cold, but not that cold!\", \n",
    "            (280, 40), xytext=(1.3, .3), xycoords=\"data\", textcoords=\"axes fraction\", fontsize=\"x-large\",\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3, rad=-0.3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49687dd4",
   "metadata": {},
   "source": [
    "## Fourth example : Averaging over polygons\n",
    "\n",
    "Because the conservative regridding method preserves areal averages, we can use xESMF to compute *exact* averages over polygons. We call it \"exact\" because is takes into account partial overlaps between the gridcells and the shapes, including potential holes. While it is fast and powerful, this polygon averaging functionality is new in xESMF and still lacks some features, like missing values handling and performance issues with high-resolution polygons.\n",
    "\n",
    "The following example grabs some polygon shapes from PAVICS' Geoserver and averages the NRCAN data over them.\n",
    "\n",
    "### Define polygon shapes\n",
    "\n",
    "This example fetches all MRC of Québec and then only selects 10 large ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412e38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owslib.wfs import WebFeatureService\n",
    "import geopandas as gpd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e793c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs_url = 'http://pavics.ouranos.ca/geoserver/wfs'\n",
    "# Connect to GeoServer WFS service.\n",
    "wfs = WebFeatureService(wfs_url, version='2.0.0')\n",
    "\n",
    "# Get the json as a binary stream\n",
    "# Here we select Quebec's MRCs polygons\n",
    "# We select only a few properties\n",
    "data = wfs.getfeature(\n",
    "    typename='public:quebec_mrc_boundaries',\n",
    "    #bbox=(-93.1, 41.1, -75.0, 49.6),\n",
    "    outputFormat='json',\n",
    "    propertyname=['the_geom', 'MRS_NM_MRC']\n",
    ")\n",
    "# Load into a GeoDataFrame by reading the json on-the-fly\n",
    "shapes_all = gpd.GeoDataFrame.from_features(json.load(data))\n",
    "shapes_all['AREA'] = shapes_all.area\n",
    "shapes = shapes_all.sort_values('AREA').iloc[18:28].drop(columns=['bbox']).set_index('MRS_NM_MRC')\n",
    "shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557fc4b",
   "metadata": {},
   "source": [
    "### Validate and simplify shapes\n",
    "\n",
    "High resolution polygons might slow down the creation of the xESMf averager object. Here we ensure polygons are simplified to a resolution 50x times finer than the input data. This should have a minimal impact on the output while still improving performance.\n",
    "\n",
    "As it is the case here, downloaded polygons sometime have topological problems which can be tested with `shapes.is_valid`. Simplifying polygons sometimes help overcome these issues, as we do here, simplifiying to 1/100th of the grid size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b084615",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes.is_valid.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a92e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only to show the decrease in size\n",
    "def count_points(elem):\n",
    "    def _count(poly):\n",
    "        return len(poly.exterior.coords) + sum(len(hole.coords) for hole in poly.interiors)\n",
    "    if hasattr(elem, '__len__'):  # then it is a MultiPolygon\n",
    "        return sum(_count(poly) for poly in elem)\n",
    "    return _count(elem)\n",
    "\n",
    "# Count the total number of nodes in the shapes:\n",
    "print('Total number of nodes in the raw shapes : ', shapes.geometry.apply(count_points).sum())\n",
    "\n",
    "min_grid_size = float(min(abs(ds_in.lat.diff('lat')).min(), abs(ds_in.lon.diff('lon')).min()))\n",
    "print(f'Minimal grid size [°] of input ds: {min_grid_size:0.3f}, we will simplify to a tolerance of {min_grid_size / 100:0.5f}')\n",
    "\n",
    "# Simplify geometries\n",
    "shapes_simp = shapes.copy()\n",
    "shapes_simp['geometry'] = shapes.simplify(min_grid_size / 100)\n",
    "\n",
    "print('Total number of nodes in the simplified shapes : ', shapes_simp.geometry.apply(count_points).sum())\n",
    "assert shapes_simp.buffer(0).is_valid.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5100e7",
   "metadata": {},
   "source": [
    "### Averaging over each polygon\n",
    "\n",
    "Performing the spatial average is as simple as regridding. We first construct a `SpatialAverager` object from the input grid and polygons, then call it with the data to average. Note that xESMf expects a list of shapes, so we pass the `shapes.geometry` series (and not the `GeoDataFrame` itself).\n",
    "\n",
    "The returned DataArray was averaged along its spatial (lat/lon) dimensions and the average over the different shapes are along the new `geom` dimension, which is in the same order as the initial GeoDataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91edab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "savg = xe.SpatialAverager(ds_in, shapes_simp.geometry)\n",
    "tn_avg = savg(ds_in.tasmin)\n",
    "tn_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968568e5",
   "metadata": {},
   "source": [
    "### Merging polygon features' properties into the result\n",
    "\n",
    "In the previous results, the polygons are indexed along the `geom` dimension, but we'd like to have the region names and properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "# Set coordinates of \"geom\" to the shapes index\n",
    "tn_avg['geom'] = shapes_simp.index.values\n",
    "\n",
    "# Get a Dataset of properties from the dataframe\n",
    "# Drop the geometries (we don't want them), convert to xarray and rename the index so it matches the one in tn_avg\n",
    "props = shapes_simp.drop(columns=['geometry']).to_xarray().rename(MRS_NM_MRC='geom')\n",
    "\n",
    "# Assign all properties as \"auxiliary\" coordinates\n",
    "tn_avg = tn_avg.assign_coords(**props.data_vars)\n",
    "tn_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1acd6",
   "metadata": {},
   "source": [
    "Or, on the contrary, we could want to merge the averaged data to the dataframe instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_data = shapes_simp.copy()\n",
    "shapes_data['tasmin'] = tn_avg.to_series()\n",
    "shapes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75728782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can plot easily the results as a choropleth map!\n",
    "ax = shapes_data.plot('tasmin', legend=True, legend_kwds={'label': 'Minimal temperature 1993-05-20 [K]'})\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_xlabel('Longitude')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
