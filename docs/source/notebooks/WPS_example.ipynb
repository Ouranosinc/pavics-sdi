{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PAVICS Web Processing Services \n",
    "PAVICS allows access to a number of different WPS services via Birdhouse\n",
    "* Each 'bird' groups a set of processing tools \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owslib.wps import WebProcessingService\n",
    "import requests\n",
    "from lxml import etree  \n",
    "import owslib\n",
    "owslib.__version__\n",
    "\n",
    "def parseStatus(execute):\n",
    "    o = requests.get(execute.statusLocation)\n",
    "    t = etree.fromstring(o.content)\n",
    "    ref = t.getchildren()[-1].getchildren()[-1].getchildren()[-1].get('{http://www.w3.org/1999/xlink}href')\n",
    "    \n",
    "    return ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### One suite of WPS tools for netcdf files resides in 'Hummingbird'\n",
    "For metadata use GetCapabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hummingbird 0.5_dev\n"
     ]
    }
   ],
   "source": [
    "# Hummingbird WPS url\n",
    "wps_url = 'https://pavics.ouranos.ca/twitcher/ows/proxy/hummingbird/wps'\n",
    "# connection\n",
    "wps = WebProcessingService(url=wps_url)\n",
    "# print wps title\n",
    "print(wps.identification.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out info on available processes (from Hummingbird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncdump \t : Run ncdump to retrieve NetCDF header metadata. \n",
      "\n",
      "spotchecker \t : Checks a single uploaded or remote dataset against a variety of compliance standards. The dataset is either in the NetCDF format or a remote OpenDAP resource. Available compliance standards are the Climate and Forecast conventions (CF) and project specific rules for CMIP6 and CORDEX. \n",
      "\n",
      "cchecker \t : Runs the IOOS Compliance Checker tool to check datasets against compliance standards. Each compliance standard is executed by a Check Suite, which functions similar to a Python standard Unit Test. A Check Suite runs one or more checks against a dataset, returning a list of Results which are then aggregated into a summary. Development and maintenance for the compliance checker is done by the Integrated Ocean Observing System (IOOS). \n",
      "\n",
      "cfchecker \t : The NetCDF Climate Forcast Conventions compliance checker by CEDA. This process allows you to run the compliance checker to check that the contents of a NetCDF file comply with the Climate and Forecasts (CF) Metadata Convention. The CF-checker was developed at the Hadley Centre for Climate Prediction and Research, UK Met Office by Rosalyn Hatcher. This work was supported by PRISM (PRogramme for Integrated Earth System Modelling). Development and maintenance for the CF-checker has now been taken over by the NCAS Computational Modelling Services (NCAS-CMS). If you have suggestions for improvement then please contact Rosalyn Hatcher at NCAS-CMS (r.s.hatcher@reading.ac.uk). \n",
      "\n",
      "cmor_checker \t : Calls the CMIP6 cmor checker to verify CMIP6 compliance.CMIP6 CMOR checker will verify that all attributes in the input file are present and conform to CMIP6 for publication into ESGF. \n",
      "\n",
      "qa_cfchecker \t : The NetCDF Climate Forcast Conventions compliance checker by DKRZ. This process allows you to run the compliance checker to check that the contents of a NetCDF file comply with the Climate and Forecasts (CF) Metadata Convention. The CF Conformance checker applies to conventions 1.4 -1.7draft. Development and maintenance for the CF-checker is done by the German Climate Computing Centre (DKRZ). If you have suggestions for improvement then please contact Heinz-Dieter Hollweg at DKRZ (hollweg@dkrz.de). \n",
      "\n",
      "qa_checker \t : The Quality Assurance checker QA-DKRZ checks conformance of meta-data of climate simulations given in NetCDF format with conventions and rules of climate model projects. At present, checking of CF Conventions, CMIP5, and CORDEX is supported. Development and maintenance for the QA checker is done by the German Climate Computing Centre (DKRZ). If you have suggestions for improvement then please contact Heinz-Dieter Hollweg at DKRZ (hollweg@dkrz.de). \n",
      "\n",
      "cdo_sinfo \t : Runs CDO to retrieve NetCDF metadata information. Calls the sinfo operator of CDO (Climate Data Operator) on a NetCDF file and returns a document with metadata information. \n",
      "\n",
      "cdo_operation \t : Calls CDO operations like monmax on a NetCDF file. \n",
      "\n",
      "cdo_copy \t : Calls CDO to copy or concatenate datasets. All input datasets need to have the same structure with the same variables on different timesteps. \n",
      "\n",
      "cdo_bbox \t : Runs CDO to clip a bounding-box from a NetCDF file. Calls the CDO (Climate Data Operators) sellonlatbox operator with a bounding-box and returns the resulting NetCDF file. \n",
      "\n",
      "cdo_indices \t : Calculates climate indices like summer days using CDO. Calls the Climate Data Operators (CDO) tool with a single dataset (NetCDF, OpenDAP) provided and uses the chosen operator to calculate climate indices written to a NetCDF file. \n",
      "\n",
      "ensembles \t : Calling cdo to calculate ensembles operations. \n",
      "\n",
      "cdo_inter_mpi \t : CDO Remapping of NetCDF File(s) with multiprocessing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for process in wps.processes:\n",
    "    print ('%s \\t : %s \\n' %(process.identifier, process.abstract))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAVICS/Hummingbird has lots of WPS services\n",
    "### Let's keep it simple with 'ncdump'  \n",
    "* Print info on WPS inputs needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ncdump to retrieve NetCDF header metadata.\n",
      "Inputs:\n",
      " *  dataset\n",
      " *  dataset_opendap\n"
     ]
    }
   ],
   "source": [
    "# ncdump\n",
    "proc_name = 'ncdump'\n",
    "process = wps.describeprocess(proc_name) # get process info\n",
    "print(process.abstract)\n",
    "print(\"Inputs:\")\n",
    "for inputs in process.dataInputs:\n",
    "    print(' * ', inputs.identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The only input we need is a dataset (url) or it's OpenDAP link\n",
    "* A simple way to find a test dataset is to access : https://pavics.ouranos.ca/thredds\n",
    "\n",
    "* Note - PAVICS also has a catalogue WPS but we will see that in other examples later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/nrcan/nrcan_canada_daily/tasmin/nrcan_canada_daily_tasmin_2013.nc\n"
     ]
    }
   ],
   "source": [
    "# Example netcdf url to NRCAN daily - tasmin 2013\n",
    "nc_url = 'https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/nrcan/nrcan_canada_daily/tasmin/nrcan_canada_daily_tasmin_2013.nc'\n",
    "print(nc_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create WPS input - Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dataset_opendap', 'https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/nrcan/nrcan_canada_daily/tasmin/nrcan_canada_daily_tasmin_2013.nc')]\n"
     ]
    }
   ],
   "source": [
    "myinputs = []\n",
    "myinputs.append(('dataset_opendap',nc_url)) # inputs : use opendap link of a single netcdf file from catalogue search to erun ncdump\n",
    "print(myinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute the WPS\n",
    "The execution is asynchronous, meaning that it does not automatically return the output. The response of the server is only a message saying that the request was accepted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncdump\n"
     ]
    }
   ],
   "source": [
    "print(proc_name)\n",
    "execute = wps.execute(proc_name, myinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wps:ExecuteResponse xmlns:gml=\"http://www.opengis.net/gml\" xmlns:ows=\"http://www.opengis.net/ows/1.1\" xmlns:wps=\"http://www.opengis.net/wps/1.0.0\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.opengis.net/wps/1.0.0 http://schemas.opengis.net/wps/1.0.0/wpsExecute_response.xsd\" service=\"WPS\" version=\"1.0.0\" xml:lang=\"en-US\" serviceInstance=\"https://pavics.ouranos.ca:443/wps?service=WPS&amp;request=GetCapabilities\" statusLocation=\"https://pavics.ouranos.ca:443/wpsoutputs/hummingbird/6ca0018a-bb58-11e8-91d6-0242ac12000d.xml\">\n",
      "  <wps:Process wps:processVersion=\"4.4.1.1\">\n",
      "    <ows:Identifier>ncdump</ows:Identifier>\n",
      "    <ows:Title>NCDump</ows:Title>\n",
      "    <ows:Abstract>Run ncdump to retrieve NetCDF header metadata.</ows:Abstract>\n",
      "  </wps:Process>\n",
      "  <wps:Status creationTime=\"2018-09-18T15:35:09Z\">\n",
      "    <wps:ProcessSucceeded>PyWPS Process NCDump finished</wps:ProcessSucceeded>\n",
      "  </wps:Status>\n",
      "  <wps:ProcessOutputs>\n",
      "    <wps:Output>\n",
      "      <ows:Identifier>output</ows:Identifier>\n",
      "      <ows:Title>NetCDF Metadata</ows:Title>\n",
      "      <ows:Abstract>NetCDF Metadata</ows:Abstract>\n",
      "      <wps:Reference xlink:href=\"https://pavics.ouranos.ca:443/wpsoutputs/hummingbird/6ca0018a-bb58-11e8-91d6-0242ac12000d/nc_dump_Qo2F86.txt\" mimeType=\"text/plain\"/>\n",
      "    </wps:Output>\n",
      "  </wps:ProcessOutputs>\n",
      "</wps:ExecuteResponse>\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "print(etree.tostring(execute.response).decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the result\n",
    "To actually parse the output, we must first make sure that the process completed server-side. \n",
    "`execute.checkStatus()` will poll the server and update its response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status:  ProcessSucceeded\n",
      "https://pavics.ouranos.ca:443/wpsoutputs/hummingbird/6ca0018a-bb58-11e8-91d6-0242ac12000d.xml\n"
     ]
    }
   ],
   "source": [
    "execute.checkStatus()\n",
    "print(\"Status: \", execute.status)\n",
    "print(execute.statusLocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can check the actual output of the process, stored as a list in the `processOutputs` attribute. In the case where the output is a reference to a file, we can get it using the `reference` attribute. The method `retrieveData` let's us fetch and retrieve the content of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output reference :\n",
      "* https://pavics.ouranos.ca:443/wpsoutputs/hummingbird/6ca0018a-bb58-11e8-91d6-0242ac12000d/nc_dump_8MSe6y.txt\n",
      "\n",
      "NCDUMP results :\n",
      " netcdf nrcan_canada_daily_tasmin_2013.nc {\n",
      "dimensions:\n",
      "\ttime = UNLIMITED ; // (365 currently)\n",
      "\tlat = 510 ;\n",
      "\tlon = 1068 ;\n",
      "\tts = 3 ;\n",
      "variables:\n",
      "\tfloat lon(lon) ;\n",
      "\t\tlon:units = \"degrees_east\" ;\n",
      "\t\tlon:long_name = \"longitude\" ;\n",
      "\t\tlon:standard_name = \"longitude\" ;\n",
      "\t\tlon:axis = \"X\" ;\n",
      "\t\tlon:_ChunkSizes = 1068 ;\n",
      "\tfloat lat(lat) ;\n",
      "\t\tlat:axis = \"Y\" ;\n",
      "\t\tlat:units = \"degrees_north\" ;\n",
      "\t\tlat:long_name = \"latitude\" ;\n",
      "\t\tlat:standard_name = \"latitude\" ;\n",
      "\t\tlat:_ChunkSizes = 510 ;\n",
      "\tshort ts(ts) ;\n",
      "\t\tts:_FillValue = -32767s ;\n",
      "\t\tts:_ChunkSizes = 3 ;\n",
      "\tshort time(time) ;\n",
      "\t\ttime:axis = \"T\" ;\n",
      "\t\ttime:units = \"days since 1950-01-01 00:00:00\" ;\n",
      "\t\ttime:long_name = \"time\" ;\n",
      "\t\ttime:standard_name = \"time\" ;\n",
      "\t\ttime:calendar = \"gregorian\" ;\n",
      "\t\ttime:_ChunkSizes = 1 ;\n",
      "\tshort time_vectors(time, ts) ;\n",
      "\t\ttime_vectors:_ChunkSizes = 1, 3 ;\n",
      "\tfloat tasmin(time, lat, lon) ;\n",
      "\t\ttasmin:long_name = \"air_temperature\" ;\n",
      "\t\ttasmin:standard_name = \"air_temperature\" ;\n",
      "\t\ttasmin:units = \"K\" ;\n",
      "\t\ttasmin:_FillValue = 9.96921e+36f ;\n",
      "\t\ttasmin:_ChunkSizes = 31, 102, 267 ;\n",
      "\n",
      "// global attributes:\n",
      "\t\t:Conventions = \"CF-1.5\" ;\n",
      "\t\t:title = \"NRCAN 10km Gridded Climate Dataset\" ;\n",
      "\t\t:history = \"2016-01-05T16:30:06: Convert from original format to NetCDF\" ;\n",
      "\t\t:institution = \"NRCAN\" ;\n",
      "\t\t:source = \"ANUSPLIN\" ;\n",
      "\t\t:redistribution = \"Redistribution policy unknown. For internal use only.\" ;\n",
      "\t\t:DODS_EXTRA.Unlimited_Dimension = \"time\" ;\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref = parseStatus(execute)\n",
    "print('Output reference :\\n*', ref)\n",
    "\n",
    "r = requests.get(ref)\n",
    "print('\\nNCDUMP results :\\n',r.text)\n",
    "\n",
    "#out = execute.processOutputs[0]\n",
    "#print(\"Output reference: \", out.reference)\n",
    "#data = out.retrieveData()\n",
    "#print(\"Data: \", data.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
